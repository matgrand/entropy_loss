{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set up a simple training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt; plt.style.use('dark_background')\n",
    "π = np.pi\n",
    "from numpy.random import uniform as uni\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_SAMPLES = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# architecture\n",
    "LATENT_DIM = 8\n",
    "class Net(nn.Module):\n",
    "    def __init__(self, in_dim, out_dim, hidden_dim=64):\n",
    "        super(Net, self).__init__()\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(in_dim, hidden_dim),\n",
    "            # nn.ReLU(),\n",
    "            # nn.Linear(hidden_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, out_dim)\n",
    "        )\n",
    "    def forward(self, x): return self.fc(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a dataset\n",
    "def create_random_signal(n_samples=N_SAMPLES, n_frqs=2):\n",
    "    # generate random frequencies\n",
    "    fs = uni(0, 5, n_frqs)\n",
    "    As = uni(0.8, 1, n_frqs)\n",
    "    φs = uni(0, 2*π, n_frqs)\n",
    "    t = np.linspace(0, 1, n_samples)\n",
    "    # generate the signal\n",
    "    x = np.sum([As[i]*np.sin(2*π*fs[i]*t+φs[i]) for i in range(n_frqs)], axis=0).astype(np.float32)\n",
    "    return x\n",
    "\n",
    "class SigDS(Dataset):\n",
    "    def __init__(self, n_ds):\n",
    "        self.n_ds = n_ds\n",
    "        self.data = torch.stack([torch.tensor(create_random_signal()) for _ in range(n_ds)])\n",
    "    def __len__(self): return self.n_ds\n",
    "    def __getitem__(self, idx): return self.data[idx]\n",
    "\n",
    "ds = SigDS(20000)\n",
    "dl = DataLoader(ds, batch_size=16, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot 10 random signals\n",
    "plt.figure(figsize=(10, 10))\n",
    "for i in range(10):\n",
    "    plt.subplot(5, 2, i+1)\n",
    "    plt.plot(ds[i])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define custom loss with custom gradient\n",
    "class HLoss1(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(HLoss1, self).__init__()\n",
    "    def forward(self, x1, x2):\n",
    "        x = x1 - x2\n",
    "        b = F.softmax(x, dim=-1) * F.log_softmax(x, dim=-1)\n",
    "        # b = -1.0 * b.sum() / x.size(0)\n",
    "        b = b.sum() / x.size(0)\n",
    "        return b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training loop\n",
    "enc = Net(N_SAMPLES, LATENT_DIM)\n",
    "dec = Net(LATENT_DIM, N_SAMPLES)\n",
    "opt = optim.Adam(list(enc.parameters()) + list(dec.parameters()), lr=3e-3)\n",
    "\n",
    "mse_loss = nn.MSELoss()\n",
    "l1_loss = nn.L1Loss()\n",
    "H_loss = HLoss1()\n",
    "\n",
    "n_epochs = 20\n",
    "lmses, lL1s, lHs = [], [], []\n",
    "for epoch in (range(n_epochs)):\n",
    "    elmse, elL1, elH = 0, 0, 0\n",
    "    for x in dl:\n",
    "        opt.zero_grad()\n",
    "\n",
    "        z = enc(x)\n",
    "        x̂ = dec(z)\n",
    "\n",
    "        lmse = mse_loss(x̂, x)\n",
    "        lL1 = l1_loss(x̂, x)\n",
    "        lH = H_loss(x̂, x)\n",
    "\n",
    "        elmse += lmse.item()\n",
    "        elL1 += lL1.item()\n",
    "        elH += lH.item()\n",
    "\n",
    "        loss = lmse\n",
    "        # loss = lL1\n",
    "        # loss = lH\n",
    "        loss.backward()\n",
    "\n",
    "        opt.step()\n",
    "\n",
    "    lmses.append(elmse/len(dl))\n",
    "    lL1s.append(elL1/len(dl))\n",
    "    lHs.append(elH/len(dl))\n",
    "\n",
    "    print(f'ep {epoch}-> mse:{lmses[-1]:.4f}, L1:{lL1s[-1]:.4f}, H:{lHs[-1]:.4f}')\n",
    "\n",
    "# plot losses\n",
    "lmses = np.array(lmses)/np.max(lmses)\n",
    "lL1s = np.array(lL1s)/np.max(lL1s)\n",
    "lHs = np.array(lHs)/np.max(lHs)\n",
    "plt.figure(figsize=(10, 2))\n",
    "plt.plot(lmses, label='mse')\n",
    "plt.yscale('log')\n",
    "plt.legend()\n",
    "plt.figure(figsize=(10, 2))\n",
    "plt.plot(lL1s, label='L1')\n",
    "plt.yscale('log')\n",
    "plt.legend()\n",
    "plt.figure(figsize=(10, 2))\n",
    "plt.plot(lHs, label='H')\n",
    "plt.yscale('log')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "print(f'train losses: mse:{lmses[-1]:.4f}, L1:{lL1s[-1]:.4f}, H:{lHs[-1]:.4f}')\n",
    "\n",
    "\n",
    "# evaluate on unseen data useing mse loss\n",
    "test_in = SigDS(100).data\n",
    "test_out = dec(enc(SigDS(100).data))\n",
    "test_loss = mse_loss(test_out, test_in)\n",
    "print(f'test loss: {test_loss}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compare input and output\n",
    "plt.figure(figsize=(10, 10))\n",
    "err = []\n",
    "for i in range(20):\n",
    "    plt.subplot(10, 2, i+1)\n",
    "    x = create_random_signal()\n",
    "    x̂ = dec(enc(torch.tensor(x).view(1,N_SAMPLES))).view(N_SAMPLES).detach().numpy()\n",
    "    err.append(np.mean((x-x̂)**2))\n",
    "    plt.plot(x, label='input')\n",
    "    plt.plot(x̂, label='output')\n",
    "    # plt.grid()\n",
    "plt.suptitle(f'mse: {np.mean(err)}')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
